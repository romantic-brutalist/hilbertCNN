{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec17238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Couldn't find a Git repository in '/home/caliban/hilbertCNN' nor in any parent directory. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/romantic-brutalist/hilbertcnn/97ba96d310274c4e87901f2352800402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import numpy as np\n",
    "from hilbert import decode, encode\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key=\"uM0HPEvEu6OyX3dTEuB4Fihgz\",\n",
    "    project_name=\"hilbertcnn\",\n",
    "    workspace=\"romantic-brutalist\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d0301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"COMET_API_KEY\"] = \"uM0HPEvEu6OyX3dTEuB4Fihgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b024166",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\"batch_size\": 64, \"num_epochs\": 5, \"learning_rate\": 0.0015,\"trainset\":\"_4layer_w_volume\",\"loss_metric\":\"MAE\",\"regularizer\":\"L1\"}\n",
    "experiment.log_parameters(hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71b7b35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e6cafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "class HilbertImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = pd.read_parquet(os.path.join(self.img_dir, annotations_file))\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, -1])\n",
    "        image = np.load(img_path)\n",
    "        label = self.img_labels.iloc[idx, :-1].values.astype(\"float64\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee75a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = HilbertImageDataset(annotations_file=\"target_line_3.parquet\",img_dir=\"imgs/train\"+hyper_params[\"trainset\"]+\"/\")\n",
    "test_ds = HilbertImageDataset(annotations_file=\"target_line_3.parquet\",img_dir=\"imgs/test\"+hyper_params[\"trainset\"]+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "830d4a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_ds, batch_size=hyper_params[\"batch_size\"], shuffle=True)\n",
    "testloader = DataLoader(test_ds, batch_size=hyper_params[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e03d65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(5, 8, 5,padding=\"same\")\n",
    "        self.pool = nn.AvgPool2d(3, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3,padding=\"same\")\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 2)\n",
    "        self.conv5 = nn.Conv2d(64, 128, 2)\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 16)\n",
    "        self.fc6 = nn.Linear(16, 8)\n",
    "        \n",
    "        self.batch1=nn.BatchNorm2d(8)\n",
    "        self.batch2=nn.BatchNorm2d(16)\n",
    "        self.batch3=nn.BatchNorm2d(32)\n",
    "        self.batch4=nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.dropout1=nn.Dropout2d(p=0.2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch1(F.relu(self.conv1(self.dropout1(x))))\n",
    "        x = self.pool(self.batch2(F.relu(self.conv2(x))))\n",
    "        x = self.pool(self.batch3(F.relu(self.conv3(self.dropout1(x)))))\n",
    "        x = self.batch4(F.relu(self.conv4(x)))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "227213b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=hyper_params[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "80ddfa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer,criterion,dataloader,epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_loss= 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.8f}')\n",
    "            experiment.log_metric(\"batch_loss\", running_loss/200)\n",
    "            running_loss = 0.0\n",
    "    experiment.log_metrics({\"loss\": total_loss/len(trainloader)}, epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a0291e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Model Training\n",
      "[1,   200] loss: 0.00043445\n",
      "[1,   400] loss: 0.00002432\n",
      "[1,   600] loss: 0.00002489\n",
      "[1,   800] loss: 0.00002307\n",
      "[1,  1000] loss: 0.00001989\n",
      "[1,  1200] loss: 0.00001607\n",
      "[1,  1400] loss: 0.00001760\n",
      "[1,  1600] loss: 0.00001747\n",
      "[1,  1800] loss: 0.00001470\n",
      "[1,  2000] loss: 0.00001522\n",
      "[1,  2200] loss: 0.00001526\n",
      "[2,   200] loss: 0.00001431\n",
      "[2,   400] loss: 0.00001468\n",
      "[2,   600] loss: 0.00001345\n",
      "[2,   800] loss: 0.00001413\n",
      "[2,  1000] loss: 0.00001688\n",
      "[2,  1200] loss: 0.00001391\n",
      "[2,  1400] loss: 0.00001468\n",
      "[2,  1600] loss: 0.00001857\n",
      "[2,  1800] loss: 0.00001400\n",
      "[2,  2000] loss: 0.00001435\n",
      "[2,  2200] loss: 0.00001674\n",
      "[3,   200] loss: 0.00001319\n",
      "[3,   400] loss: 0.00001423\n",
      "[3,   600] loss: 0.00001526\n",
      "[3,   800] loss: 0.00001660\n",
      "[3,  1000] loss: 0.00001396\n",
      "[3,  1200] loss: 0.00001326\n",
      "[3,  1400] loss: 0.00001515\n",
      "[3,  1600] loss: 0.00001825\n",
      "[3,  1800] loss: 0.00001428\n",
      "[3,  2000] loss: 0.00001506\n",
      "[3,  2200] loss: 0.00001457\n",
      "[4,   200] loss: 0.00001395\n",
      "[4,   400] loss: 0.00001338\n",
      "[4,   600] loss: 0.00001285\n",
      "[4,   800] loss: 0.00001662\n",
      "[4,  1000] loss: 0.00001644\n",
      "[4,  1200] loss: 0.00001398\n",
      "[4,  1400] loss: 0.00001576\n",
      "[4,  1600] loss: 0.00001531\n",
      "[4,  1800] loss: 0.00001494\n",
      "[4,  2000] loss: 0.00001410\n",
      "[4,  2200] loss: 0.00001652\n",
      "[5,   200] loss: 0.00001396\n",
      "[5,   400] loss: 0.00001598\n",
      "[5,   600] loss: 0.00001352\n",
      "[5,   800] loss: 0.00001747\n",
      "[5,  1000] loss: 0.00001724\n",
      "[5,  1200] loss: 0.00001511\n",
      "[5,  1400] loss: 0.00001391\n",
      "[5,  1600] loss: 0.00001339\n",
      "[5,  1800] loss: 0.00001377\n",
      "[5,  2000] loss: 0.00001406\n",
      "[5,  2200] loss: 0.00001488\n"
     ]
    }
   ],
   "source": [
    "with experiment.train():\n",
    "    print(\"Running Model Training\")\n",
    "    for epoch in range(hyper_params[\"num_epochs\"]):\n",
    "        train(net, optimizer, criterion, trainloader, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff54b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml.integration.pytorch import log_model\n",
    "#log_model(experiment, net, model_name=\"4_layer_w_volume_classic_CNN_mae_slope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4f5dc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = {\n",
    "    \"epoch\": epoch,\n",
    "    \"model_state_dict\": net.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"criterion\":criterion}\n",
    "log_model(experiment, model_checkpoint, model_name=\"4_layer_w_volume_classic_CNN_mse_line_3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5829c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(5, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (apool): AdaptiveMaxPool2d(output_size=4)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc5): Linear(in_features=16, out_features=8, bias=True)\n",
       "  (batch1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout1): Dropout2d(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from comet_ml.integration.pytorch import load_model\n",
    "model = Net()\n",
    "\n",
    "# Load the model state dict from a Comet Experiment\n",
    "checkpoint = load_model(\"experiment://ebb9475c2e544221bada3876eb4d95ba/4_layer_w_volume_classic_CNN_mae_line_3\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15494d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(5, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (apool): AdaptiveMaxPool2d(output_size=4)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc5): Linear(in_features=16, out_features=8, bias=True)\n",
       "  (batch1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout1): Dropout2d(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c56a4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "cols = list(pd.concat([pd.read_parquet(\"imgs/train\"+hyper_params[\"trainset\"]+\"/target_line_3.parquet\"),\n",
    "pd.read_parquet(\"imgs/test\"+hyper_params[\"trainset\"]+\"/target_line_3.parquet\")]).iloc[:,:-1].columns)\n",
    "fcs = [[i+\"_target\",i+\"_pred\"] for i in cols]\n",
    "fullcols = [item for sublist in fcs for item in sublist]\n",
    "tl = []\n",
    "for images, labels in dataiter:\n",
    "    images = images.float().to(device)\n",
    "    labels = labels.float().to(device)\n",
    "    outputs = net(images)\n",
    "    evaldf = pd.DataFrame(labels.cpu(),columns=[i+\"_target\" for i in cols]).join(pd.DataFrame(outputs.cpu().tolist(),columns=[i+\"_pred\" for i in cols]))\n",
    "    tl.append(evaldf[fullcols])\n",
    "tf = pd.concat(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4b8417f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low_5_target</th>\n",
       "      <th>Low_5_pred</th>\n",
       "      <th>High_5_target</th>\n",
       "      <th>High_5_pred</th>\n",
       "      <th>Low_10_target</th>\n",
       "      <th>Low_10_pred</th>\n",
       "      <th>High_10_target</th>\n",
       "      <th>High_10_pred</th>\n",
       "      <th>Low_15_target</th>\n",
       "      <th>Low_15_pred</th>\n",
       "      <th>High_15_target</th>\n",
       "      <th>High_15_pred</th>\n",
       "      <th>Low_20_target</th>\n",
       "      <th>Low_20_pred</th>\n",
       "      <th>High_20_target</th>\n",
       "      <th>High_20_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "      <td>15830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.001327</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>-0.001321</td>\n",
       "      <td>-0.001430</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>-0.001323</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>-0.001317</td>\n",
       "      <td>-0.001663</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.002528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001651</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.000492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.061664</td>\n",
       "      <td>-0.007691</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>-0.057036</td>\n",
       "      <td>-0.010623</td>\n",
       "      <td>-0.025510</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>-0.066908</td>\n",
       "      <td>-0.006971</td>\n",
       "      <td>-0.043833</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>-0.059140</td>\n",
       "      <td>-0.007297</td>\n",
       "      <td>-0.039862</td>\n",
       "      <td>0.001875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.001718</td>\n",
       "      <td>-0.000859</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.001574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>-0.002550</td>\n",
       "      <td>-0.001288</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>-0.002799</td>\n",
       "      <td>-0.001727</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>0.002264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000879</td>\n",
       "      <td>-0.000486</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>-0.000905</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>-0.000934</td>\n",
       "      <td>-0.000980</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.001448</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.002423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.000363</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>-0.000696</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.043472</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.025916</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.059302</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.036149</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.049969</td>\n",
       "      <td>0.009263</td>\n",
       "      <td>0.036223</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>0.060177</td>\n",
       "      <td>0.007294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Low_5_target    Low_5_pred  High_5_target   High_5_pred  Low_10_target  \\\n",
       "count  15830.000000  15830.000000   15830.000000  15830.000000   15830.000000   \n",
       "mean      -0.001327     -0.000737       0.001359      0.002236      -0.001321   \n",
       "std        0.001651      0.001046       0.001668      0.000777       0.002677   \n",
       "min       -0.061664     -0.007691      -0.000042      0.001150      -0.057036   \n",
       "25%       -0.001718     -0.000859       0.000385      0.001830      -0.002187   \n",
       "50%       -0.000879     -0.000486       0.000906      0.002078      -0.000905   \n",
       "75%       -0.000363     -0.000184       0.001752      0.002354       0.000057   \n",
       "max        0.000047      0.000428       0.043472      0.008915       0.025916   \n",
       "\n",
       "        Low_10_pred  High_10_target  High_10_pred  Low_15_target  \\\n",
       "count  15830.000000    15830.000000  15830.000000   15830.000000   \n",
       "mean      -0.001430        0.001369      0.002536      -0.001323   \n",
       "std        0.000749        0.002729      0.000691       0.003339   \n",
       "min       -0.010623       -0.025510      0.001310      -0.066908   \n",
       "25%       -0.001574        0.000000      0.002178      -0.002550   \n",
       "50%       -0.001302        0.000943      0.002396      -0.000934   \n",
       "75%       -0.001038        0.002256      0.002648       0.000360   \n",
       "max        0.000087        0.059302      0.009782       0.036149   \n",
       "\n",
       "        Low_15_pred  High_15_target  High_15_pred  Low_20_target  \\\n",
       "count  15830.000000    15830.000000  15830.000000   15830.000000   \n",
       "mean      -0.001121        0.001363      0.003019      -0.001317   \n",
       "std        0.000756        0.003366      0.000678       0.003926   \n",
       "min       -0.006971       -0.043833      0.002211      -0.059140   \n",
       "25%       -0.001288       -0.000299      0.002667      -0.002799   \n",
       "50%       -0.000980        0.000960      0.002860      -0.000927   \n",
       "75%       -0.000696        0.002591      0.003106       0.000636   \n",
       "max        0.000171        0.049969      0.009263       0.036223   \n",
       "\n",
       "        Low_20_pred  High_20_target  High_20_pred  \n",
       "count  15830.000000    15830.000000  15830.000000  \n",
       "mean      -0.001663        0.001372      0.002528  \n",
       "std        0.000828        0.003964      0.000492  \n",
       "min       -0.007297       -0.039862      0.001875  \n",
       "25%       -0.001727       -0.000541      0.002264  \n",
       "50%       -0.001448        0.000955      0.002423  \n",
       "75%       -0.001247        0.002863      0.002609  \n",
       "max       -0.000841        0.060177      0.007294  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ba0210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf[\"High_Slope_pred_n\"] = (tf[\"High_Slope_pred\"]-tf[\"High_Slope_pred\"].mean())/tf[\"High_Slope_pred\"].std()\n",
    "tf[\"Low_Slope_pred_n\"] = (tf[\"Low_Slope_pred\"]-tf[\"Low_Slope_pred\"].mean())/tf[\"Low_Slope_pred\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79d298d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low_5_target</th>\n",
       "      <th>Low_5_pred</th>\n",
       "      <th>High_5_target</th>\n",
       "      <th>High_5_pred</th>\n",
       "      <th>Low_10_target</th>\n",
       "      <th>Low_10_pred</th>\n",
       "      <th>High_10_target</th>\n",
       "      <th>High_10_pred</th>\n",
       "      <th>Low_15_target</th>\n",
       "      <th>Low_15_pred</th>\n",
       "      <th>High_15_target</th>\n",
       "      <th>High_15_pred</th>\n",
       "      <th>Low_20_target</th>\n",
       "      <th>Low_20_pred</th>\n",
       "      <th>High_20_target</th>\n",
       "      <th>High_20_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000534</td>\n",
       "      <td>-0.000758</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>-0.000925</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>-0.000492</td>\n",
       "      <td>-0.001450</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.002283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000701</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.001539</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.001550</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>-0.000488</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.002401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000831</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>-0.001573</td>\n",
       "      <td>-0.001569</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.001576</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>-0.000513</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.002432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003348</td>\n",
       "      <td>-0.000407</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>-0.002580</td>\n",
       "      <td>-0.001033</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.001078</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>-0.001569</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>-0.001576</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>-0.000513</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.002432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.000369</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.001826</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.001800</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>-0.000738</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.002702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.008028</td>\n",
       "      <td>-0.001183</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.001940</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>-0.000830</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.002821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.005083</td>\n",
       "      <td>-0.001155</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>-0.001907</td>\n",
       "      <td>-0.003599</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>-0.009294</td>\n",
       "      <td>-0.001870</td>\n",
       "      <td>-0.005343</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>-0.009048</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.007111</td>\n",
       "      <td>0.002786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.000278</td>\n",
       "      <td>-0.000507</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>-0.001139</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.001978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>-0.001690</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>-0.001681</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>-0.000617</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.002559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15830 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Low_5_target  Low_5_pred  High_5_target  High_5_pred  Low_10_target  \\\n",
       "0      -0.000534   -0.000758       0.000814     0.001154      -0.000925   \n",
       "1      -0.000701   -0.000852       0.000240     0.001268      -0.000138   \n",
       "2      -0.000831   -0.000877       0.000326     0.001298      -0.001573   \n",
       "3      -0.003348   -0.000407       0.000237     0.000758      -0.002580   \n",
       "4      -0.000004   -0.000877       0.002267     0.001298       0.000625   \n",
       "..           ...         ...            ...          ...            ...   \n",
       "17     -0.000369   -0.001089       0.000773     0.001559      -0.000005   \n",
       "18     -0.008028   -0.001183       0.000567     0.001675      -0.005420   \n",
       "19     -0.005083   -0.001155       0.000072     0.001641      -0.007304   \n",
       "20     -0.000278   -0.000507       0.001038     0.000863       0.000134   \n",
       "21     -0.000005   -0.000977       0.001581     0.001421       0.000870   \n",
       "\n",
       "    Low_10_pred  High_10_target  High_10_pred  Low_15_target  Low_15_pred  \\\n",
       "0     -0.001427        0.000603      0.000377      -0.000492    -0.001450   \n",
       "1     -0.001539        0.001010      0.000497      -0.000046    -0.001550   \n",
       "2     -0.001569        0.000453      0.000529      -0.000255    -0.001576   \n",
       "3     -0.001033       -0.000470     -0.000051      -0.000752    -0.001078   \n",
       "4     -0.001569        0.002336      0.000529       0.000599    -0.001576   \n",
       "..          ...             ...           ...            ...          ...   \n",
       "17    -0.001826        0.000758      0.000803      -0.000050    -0.001800   \n",
       "18    -0.001940        0.005737      0.000926       0.001644    -0.001900   \n",
       "19    -0.001907       -0.003599      0.000889      -0.009294    -0.001870   \n",
       "20    -0.001139        0.001349      0.000065      -0.000468    -0.001184   \n",
       "21    -0.001690        0.001591      0.000658       0.001586    -0.001681   \n",
       "\n",
       "    High_15_target  High_15_pred  Low_20_target  Low_20_pred  High_20_target  \\\n",
       "0         0.001578      0.001396      -0.000041    -0.000390        0.001482   \n",
       "1         0.001107      0.001504       0.000185    -0.000488        0.001389   \n",
       "2         0.002564      0.001532       0.000713    -0.000513        0.002833   \n",
       "3         0.001318      0.000993       0.000278    -0.000019        0.001631   \n",
       "4         0.001797      0.001532      -0.000133    -0.000513        0.001963   \n",
       "..             ...           ...            ...          ...             ...   \n",
       "17        0.001874      0.001775      -0.000738    -0.000732        0.002298   \n",
       "18        0.007611      0.001883       0.001540    -0.000830        0.005157   \n",
       "19       -0.005343      0.001851      -0.009048    -0.000801       -0.007111   \n",
       "20        0.001122      0.001108      -0.000236    -0.000127        0.000598   \n",
       "21        0.003029      0.001647       0.001188    -0.000617        0.002345   \n",
       "\n",
       "    High_20_pred  \n",
       "0       0.002283  \n",
       "1       0.002401  \n",
       "2       0.002432  \n",
       "3       0.001865  \n",
       "4       0.002432  \n",
       "..           ...  \n",
       "17      0.002702  \n",
       "18      0.002821  \n",
       "19      0.002786  \n",
       "20      0.001978  \n",
       "21      0.002559  \n",
       "\n",
       "[15830 rows x 16 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b51d879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl=[]\n",
    "margin=5\n",
    "for k in range(1,31):\n",
    "    profit = 1\n",
    "    for i,row in tf.iloc[-50*(k+1):-50*k].iterrows():\n",
    "        rnd = np.random.rand()\n",
    "        if abs(row.High_30_pred)>abs(row.Low_30_pred):\n",
    "            if row.High_30_pred<=row.High_30_target:\n",
    "                if rnd>0.3:\n",
    "                    profit*=1+row.High_30_pred*margin\n",
    "                else:\n",
    "                    profit*=(1-0.0025*margin)\n",
    "        else:\n",
    "            if row.Low_30_pred>=row.Low_30_target:\n",
    "                if rnd>0.3:\n",
    "                    profit*=1+abs(row.Low_30_pred)*margin\n",
    "                else:\n",
    "                    profit*=(1-0.0025*margin)\n",
    "\n",
    "        profit*=0.9998\n",
    "    pl.append(profit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dce0d0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0673509123909688,\n",
       " 1.1238975005714207,\n",
       " 1.0179766104314514,\n",
       " 1.1487265083205547,\n",
       " 1.272956367423118,\n",
       " 1.1580981473119594,\n",
       " 1.0877998905626058,\n",
       " 1.1984989752168203,\n",
       " 1.0348282767472443,\n",
       " 1.047606543957888,\n",
       " 1.0763505198841317,\n",
       " 0.9908169899480509,\n",
       " 1.0430807761777416,\n",
       " 1.0931483750336155,\n",
       " 1.2296696447347297,\n",
       " 1.0701848705406514,\n",
       " 1.1747573886805607,\n",
       " 1.2059888936603302,\n",
       " 1.0837346684629348,\n",
       " 1.1692219806322768,\n",
       " 1.1686494699488508,\n",
       " 1.1047820862622317,\n",
       " 1.2680866808671198,\n",
       " 1.1824812169368362,\n",
       " 1.0516656427751156,\n",
       " 1.0866221544899486,\n",
       " 1.0687716026579372,\n",
       " 1.0256492916697946,\n",
       " 1.2947348324054557,\n",
       " 1.083971900212829]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0312f6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.578952832384328"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pl).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "300c712c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/romantic-brutalist/hilbertcnn/96e1ccf1adcf4fcdb834346f05753b2f\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     train_batch_loss [110] : (0.06814029417932034, 0.25200512740761044)\n",
      "COMET INFO:     train_loss [10]        : (0.07008739145824767, 0.14456800313195575)\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     batch_size    : 64\n",
      "COMET INFO:     learning_rate : 0.0015\n",
      "COMET INFO:     loss_metric   : MAE\n",
      "COMET INFO:     num_epochs    : 10\n",
      "COMET INFO:     trainset      : _4layer_w_volume\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model-element       : 2 (2.09 MB)\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     os packages         : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1488d42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
