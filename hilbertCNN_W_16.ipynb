{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d245d2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/romantic-brutalist/hilbertcnn/0a4b768773a14b40bc703a430ba64e98\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     train_batch_loss [410] : (1.1301876750167139e-05, 0.0006158257915330978)\n",
      "COMET INFO:     train_loss [82]        : (1.4249053983346409e-05, 0.00012641356137141452)\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     batch_size    : 64\n",
      "COMET INFO:     learning_rate : 0.0015\n",
      "COMET INFO:     loss_metric   : MSE\n",
      "COMET INFO:     num_epochs    : 5\n",
      "COMET INFO:     regularizer   : L1\n",
      "COMET INFO:     trainset      : _4layer_w_volume\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (11.34 MB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/romantic-brutalist/hilbertcnn/80af5f3cad3747c09c815d1cdd19e130\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import numpy as np\n",
    "from hilbert import decode, encode\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from typing import Any, Callable, List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key=\"uM0HPEvEu6OyX3dTEuB4Fihgz\",\n",
    "    project_name=\"hilbertcnn\",\n",
    "    workspace=\"romantic-brutalist\",\n",
    ")\n",
    "import os\n",
    "os.environ[\"COMET_API_KEY\"] = \"uM0HPEvEu6OyX3dTEuB4Fihgz\"\n",
    "hyper_params = {\"batch_size\": 64, \"num_epochs\": 5, \"learning_rate\": 0.0015,\"trainset\":\"_4layer_w_volume\",\"loss_metric\":\"MSE\",\"regularizer\":\"L1\"}\n",
    "experiment.log_parameters(hyper_params)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "class HilbertImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = pd.read_parquet(os.path.join(self.img_dir, annotations_file))\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path1 = os.path.join(self.img_dir, self.img_labels.iloc[idx, -1])\n",
    "        img_path2 = os.path.join(self.img_dir, \"s_\"+self.img_labels.iloc[idx, -1])\n",
    "        img_path3 = os.path.join(self.img_dir, \"s8_\"+self.img_labels.iloc[idx, -1])\n",
    "        \n",
    "        image1 = np.load(img_path1)\n",
    "        image2 = np.load(img_path2)\n",
    "        image3 = np.load(img_path3)\n",
    "        \n",
    "        \n",
    "        label = self.img_labels.iloc[idx, :-1].values.astype(\"float64\")\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image1)\n",
    "            image2 = self.transform(image2)\n",
    "            image2 = self.transform(image3)\n",
    "            \n",
    "            \n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image1,image2,image3, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fec75707",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = HilbertImageDataset(annotations_file=\"target_next_20.parquet\",img_dir=\"imgs/train\"+hyper_params[\"trainset\"]+\"/\")\n",
    "test_ds = HilbertImageDataset(annotations_file=\"target_next_20.parquet\",img_dir=\"imgs/test\"+hyper_params[\"trainset\"]+\"/\")\n",
    "trainloader = DataLoader(train_ds, batch_size=hyper_params[\"batch_size\"], shuffle=True)\n",
    "testloader = DataLoader(test_ds, batch_size=hyper_params[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e6de1e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 5, 32, 32]),\n",
       " torch.Size([64, 5, 16, 16]),\n",
       " torch.Size([64, 5, 8, 8]),\n",
       " torch.Size([64, 8]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b,c,d = next(iter(testloader))\n",
    "a.shape,b.shape,c.shape,d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "459495a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_w_16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1a = nn.Conv2d(5, 8, 5,dilation=4,padding=\"same\")\n",
    "        torch.nn.init.xavier_uniform_(self.conv1a.weight)\n",
    "        \n",
    "        self.conv2a = nn.Conv2d(8, 16, 5,dilation=3,padding=\"same\")\n",
    "        torch.nn.init.xavier_uniform_(self.conv2a.weight)\n",
    "        self.conv3a = nn.Conv2d(16, 24, 3,dilation=2)\n",
    "        self.conv4a = nn.Conv2d(24, 48, 2)\n",
    "        self.conv5a = nn.Conv2d(48, 64, 2)\n",
    "        \n",
    "        self.conv1b = nn.Conv2d(5, 8, 4,dilation=3,padding=\"same\")\n",
    "        torch.nn.init.xavier_uniform_(self.conv1b.weight)\n",
    "        \n",
    "        self.conv2b = nn.Conv2d(8, 16, 3,dilation=2,padding=\"same\")\n",
    "        torch.nn.init.xavier_uniform_(self.conv2b.weight)\n",
    "        self.conv3b = nn.Conv2d(16, 24, 2,dilation=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(5, 8, 5,dilation=4,padding=\"same\")\n",
    "        torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        self.pool = nn.MaxPool2d(3, 2)\n",
    "        self.pool2 = nn.AvgPool2d(3, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(8, 16, 5,dilation=3,padding=\"same\")\n",
    "        torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16, 24, 3,dilation=2)\n",
    "        self.conv4 = nn.Conv2d(24, 48, 2)\n",
    "        self.conv5 = nn.Conv2d(48, 64, 2)\n",
    "        self.conv6 = nn.Conv2d(64, 128, 1)\n",
    "        \n",
    "        self.fc1a = nn.Linear(600, 512)\n",
    "        self.fc2a = nn.Linear(512, 128)\n",
    "        \n",
    "        self.fc1b = nn.Linear(600, 512)\n",
    "        self.fc2b = nn.Linear(512, 128)\n",
    "        \n",
    "        self.fc1c = nn.Linear(216, 128)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(1152, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        \n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.fc7 = nn.Linear(64, 16)\n",
    "        \n",
    "        self.fc8 = nn.Linear(16, 8)\n",
    "        \n",
    "        self.batch1=nn.BatchNorm2d(8)\n",
    "        self.batch2=nn.BatchNorm2d(16)\n",
    "        self.batch3=nn.BatchNorm2d(24)\n",
    "        self.batch4=nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.dropout1=nn.Dropout2d(p=0.2)\n",
    "        \n",
    "\n",
    "    def forward(self, xl):\n",
    "        x1=xl[0]\n",
    "        x2=xl[1]\n",
    "        x3=xl[2]\n",
    "        \n",
    "        x2 = self.dropout1(self.batch1(F.relu(self.conv1a(x2))))\n",
    "        x2 = self.batch2(F.relu(self.conv2a(x2)))\n",
    "        x2 = self.pool2(self.batch3(F.relu(self.conv3a(x2))))\n",
    "\n",
    "        x3 = self.dropout1(self.batch1(F.relu(self.conv1b(x3))))\n",
    "        x3 = self.batch2(F.relu(self.conv2b(x3)))\n",
    "        x3 = self.pool2(self.batch3(F.relu(self.conv3b(x3))))\n",
    "        \n",
    "        \n",
    "        \n",
    "        x1 = self.dropout1(self.batch1(F.relu(self.conv1(x1))))\n",
    "        x1 = self.pool(self.batch2(F.relu(self.conv2(x1))))\n",
    "        x1 = self.pool2(self.batch3(F.relu(self.conv3(x1))))\n",
    "        x1 = F.relu(self.conv4(x1))\n",
    "        x1 = F.relu(self.conv5(x1))\n",
    "        x1 = F.relu(self.conv6(x1))\n",
    "        \n",
    "        x1 = torch.flatten(x1, 1) # flatten all dimensions except batch\n",
    "        x2 = torch.flatten(x2, 1) # flatten all dimensions except batch\n",
    "        x3 = torch.flatten(x3, 1) # flatten all dimensions except batch\n",
    "        #\n",
    "        x1 = F.relu(self.fc1(x1))\n",
    "        x1 = F.relu(self.fc2(x1))\n",
    "        #x1 = F.relu(self.fc3(x1))\n",
    "        \n",
    "        x2 = F.relu(self.fc1a(x2))\n",
    "        x2 = F.relu(self.fc2a(x2))\n",
    "        \n",
    "        x3 = F.relu(self.fc1c(x3))\n",
    "        #print(x1.shape,x2.shape,x3.shape)\n",
    "        x=torch.cat([x1,x2,x3],1)\n",
    "        \n",
    "        #print(x1.shape,x2.shape,x3.shape)\n",
    "        \n",
    "        \n",
    "        x = F.leaky_relu(self.fc4(x))\n",
    "        x = F.leaky_relu(self.fc5(x))\n",
    "        \n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        x = self.fc8(x)\n",
    "        \n",
    "        return x\n",
    "net=Net_w_16().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "9b1aeffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=hyper_params[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "26793640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer,criterion,dataloader,epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_loss= 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs1,inputs2,inputs3, labels = data\n",
    "        inputs1 = inputs1.float().to(device)\n",
    "        inputs2 = inputs2.float().to(device)\n",
    "        inputs3 = inputs3.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model([inputs1,inputs2,inputs3])\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.8f}')\n",
    "            experiment.log_metric(\"batch_loss\", running_loss/200)\n",
    "            running_loss = 0.0\n",
    "    print(\"total loss:\",total_loss/len(trainloader))\n",
    "    experiment.log_metrics({\"loss\": total_loss/len(trainloader)}, epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "1499a8b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Model Training\n",
      "[1,   200] loss: 0.00036569\n",
      "[1,   400] loss: 0.00001747\n",
      "[1,   600] loss: 0.00002057\n",
      "[1,   800] loss: 0.00001724\n",
      "[1,  1000] loss: 0.00001581\n",
      "total loss: 8.009195776433589e-05\n",
      "[2,   200] loss: 0.00002222\n",
      "[2,   400] loss: 0.00001444\n",
      "[2,   600] loss: 0.00001507\n",
      "[2,   800] loss: 0.00001757\n",
      "[2,  1000] loss: 0.00001466\n",
      "total loss: 1.646378291134594e-05\n",
      "[3,   200] loss: 0.00001632\n",
      "[3,   400] loss: 0.00001351\n",
      "[3,   600] loss: 0.00001607\n",
      "[3,   800] loss: 0.00001490\n",
      "[3,  1000] loss: 0.00001641\n",
      "total loss: 1.5375164977652322e-05\n",
      "[4,   200] loss: 0.00001493\n",
      "[4,   400] loss: 0.00001393\n",
      "[4,   600] loss: 0.00001471\n",
      "[4,   800] loss: 0.00001426\n",
      "[4,  1000] loss: 0.00001842\n",
      "total loss: 1.5116858490153429e-05\n",
      "[5,   200] loss: 0.00001438\n",
      "[5,   400] loss: 0.00001310\n",
      "[5,   600] loss: 0.00001635\n",
      "[5,   800] loss: 0.00001421\n",
      "[5,  1000] loss: 0.00001393\n",
      "total loss: 1.5053633822559927e-05\n",
      "[6,   200] loss: 0.00001833\n",
      "[6,   400] loss: 0.00001266\n",
      "[6,   600] loss: 0.00001572\n",
      "[6,   800] loss: 0.00001530\n",
      "[6,  1000] loss: 0.00001397\n",
      "total loss: 1.5080321453795909e-05\n",
      "[7,   200] loss: 0.00001441\n",
      "[7,   400] loss: 0.00001406\n",
      "[7,   600] loss: 0.00001508\n",
      "[7,   800] loss: 0.00001741\n",
      "[7,  1000] loss: 0.00001418\n",
      "total loss: 1.5043392947732344e-05\n",
      "[8,   200] loss: 0.00001370\n",
      "[8,   400] loss: 0.00001641\n",
      "[8,   600] loss: 0.00001705\n",
      "[8,   800] loss: 0.00001459\n",
      "[8,  1000] loss: 0.00001413\n",
      "total loss: 1.4993508753527088e-05\n",
      "[9,   200] loss: 0.00001718\n",
      "[9,   400] loss: 0.00001354\n",
      "[9,   600] loss: 0.00001431\n",
      "[9,   800] loss: 0.00001394\n",
      "[9,  1000] loss: 0.00001596\n",
      "total loss: 1.4855602622574257e-05\n",
      "[10,   200] loss: 0.00001252\n",
      "[10,   400] loss: 0.00001568\n",
      "[10,   600] loss: 0.00001671\n",
      "[10,   800] loss: 0.00001440\n",
      "[10,  1000] loss: 0.00001570\n",
      "total loss: 1.4905393771552693e-05\n"
     ]
    }
   ],
   "source": [
    "with experiment.train():\n",
    "    print(\"Running Model Training\")\n",
    "    for epoch in range(10):\n",
    "        train(net, optimizer, criterion, trainloader, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f324e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml.integration.pytorch import log_model\n",
    "model_checkpoint = {\n",
    "    \"epoch\": epoch,\n",
    "    \"model_state_dict\": net.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"criterion\":criterion}\n",
    "log_model(experiment, model_checkpoint, model_name=\"4_layer_w_volume_w_16_8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "1e2a519f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.1805e-03,  3.6973e-03, -1.7843e-03,  5.4571e-03, -1.0036e-03,\n",
       "          6.2311e-03,  5.3690e-04,  6.3396e-03],\n",
       "        [-3.7368e-03,  4.3886e-03, -2.2752e-03,  6.0020e-03, -1.4350e-03,\n",
       "          6.7530e-03, -6.5945e-05,  6.8458e-03],\n",
       "        [-1.0596e-02,  1.3559e-02, -9.7040e-03,  1.2940e-02, -7.3163e-03,\n",
       "          1.2029e-02, -7.0113e-03,  1.3622e-02],\n",
       "        [-2.7244e-04,  3.1722e-04,  5.7148e-04,  2.8421e-03,  1.3698e-03,\n",
       "          3.5898e-03,  3.0451e-03,  3.7166e-03],\n",
       "        [-4.0777e-03,  4.8020e-03, -2.6595e-03,  6.3121e-03, -1.6198e-03,\n",
       "          7.0011e-03, -2.2823e-04,  7.1486e-03],\n",
       "        [-1.3922e-03,  1.6295e-03, -3.5591e-04,  3.9697e-03,  2.2267e-04,\n",
       "          4.5406e-03,  2.0568e-03,  4.7676e-03],\n",
       "        [-4.0898e-03,  4.8471e-03, -2.6477e-03,  6.3334e-03, -1.6535e-03,\n",
       "          7.0242e-03, -2.9288e-04,  7.1426e-03],\n",
       "        [-3.1742e-03,  3.6226e-03, -1.7778e-03,  5.4854e-03, -9.8559e-04,\n",
       "          6.1836e-03,  5.0711e-04,  6.2804e-03],\n",
       "        [-2.4585e-03,  2.7117e-03, -1.1713e-03,  4.8446e-03, -4.5133e-04,\n",
       "          5.4944e-03,  1.2092e-03,  5.5902e-03],\n",
       "        [-1.8385e-03,  2.0832e-03, -7.5689e-04,  4.3943e-03, -1.1981e-04,\n",
       "          4.9736e-03,  1.6723e-03,  5.1769e-03],\n",
       "        [-9.8550e-04,  1.1985e-03,  8.8282e-05,  3.4900e-03,  6.1975e-04,\n",
       "          4.1792e-03,  2.4184e-03,  4.3902e-03],\n",
       "        [-1.2274e-03,  1.4659e-03, -1.6417e-04,  3.7560e-03,  3.8186e-04,\n",
       "          4.3882e-03,  2.1978e-03,  4.6106e-03],\n",
       "        [-6.9011e-04,  8.9407e-04,  2.4465e-04,  3.2144e-03,  9.0231e-04,\n",
       "          3.9208e-03,  2.7139e-03,  4.1361e-03],\n",
       "        [-1.5399e-03,  1.7351e-03, -4.6328e-04,  4.1110e-03,  1.2375e-04,\n",
       "          4.6526e-03,  1.8922e-03,  4.8891e-03],\n",
       "        [-1.2413e-03,  1.4837e-03, -1.8765e-04,  3.7839e-03,  3.7254e-04,\n",
       "          4.3962e-03,  2.2037e-03,  4.6134e-03],\n",
       "        [-3.9032e-03,  4.5603e-03, -2.4075e-03,  6.1121e-03, -1.5079e-03,\n",
       "          6.8608e-03, -1.4482e-04,  6.9611e-03],\n",
       "        [-8.4521e-04,  1.0654e-03,  1.9208e-04,  3.3215e-03,  7.6906e-04,\n",
       "          4.0408e-03,  2.5894e-03,  4.2597e-03],\n",
       "        [ 5.0470e-05, -1.7824e-04,  8.5726e-04,  2.5133e-03,  1.8128e-03,\n",
       "          3.2875e-03,  3.3567e-03,  3.3232e-03],\n",
       "        [-2.0287e-03,  2.2259e-03, -7.9472e-04,  4.3942e-03, -1.2624e-04,\n",
       "          5.1016e-03,  1.7059e-03,  5.2074e-03],\n",
       "        [-4.3340e-03,  5.2189e-03, -2.8590e-03,  6.5352e-03, -1.8227e-03,\n",
       "          7.1637e-03, -4.9473e-04,  7.3033e-03],\n",
       "        [-8.9687e-03,  1.2382e-02, -7.5333e-03,  1.1204e-02, -5.8918e-03,\n",
       "          1.0436e-02, -5.7028e-03,  1.1261e-02],\n",
       "        [-7.3254e-03,  9.8767e-03, -5.7837e-03,  9.5580e-03, -4.4197e-03,\n",
       "          9.1661e-03, -3.9060e-03,  9.6915e-03],\n",
       "        [-3.7437e-04,  2.8583e-04,  5.7595e-04,  2.7769e-03,  1.4758e-03,\n",
       "          3.5539e-03,  3.1503e-03,  3.6288e-03],\n",
       "        [-1.6858e-04, -3.7100e-04,  7.6225e-04,  2.4520e-03,  1.9558e-03,\n",
       "          3.3764e-03,  3.5593e-03,  3.3028e-03],\n",
       "        [-9.3148e-04,  1.0797e-03,  1.9138e-04,  3.3224e-03,  7.7838e-04,\n",
       "          4.0560e-03,  2.5824e-03,  4.2541e-03],\n",
       "        [ 9.5759e-05, -1.8602e-04,  8.7595e-04,  2.5266e-03,  1.8004e-03,\n",
       "          3.2880e-03,  3.3266e-03,  3.3362e-03],\n",
       "        [-5.8839e-03,  6.8417e-03, -4.0475e-03,  7.6966e-03, -2.7411e-03,\n",
       "          8.1419e-03, -1.5186e-03,  8.3152e-03],\n",
       "        [-2.5938e-04,  2.3279e-04,  6.1540e-04,  2.7627e-03,  1.4674e-03,\n",
       "          3.5414e-03,  3.1245e-03,  3.6426e-03],\n",
       "        [-3.8241e-03,  4.4611e-03, -2.3291e-03,  6.0309e-03, -1.4737e-03,\n",
       "          6.8225e-03, -6.7048e-05,  6.9104e-03],\n",
       "        [-2.9231e-04,  3.8903e-04,  5.3453e-04,  2.8935e-03,  1.2988e-03,\n",
       "          3.6319e-03,  2.9945e-03,  3.7787e-03],\n",
       "        [-2.6358e-03,  2.9747e-03, -1.3619e-03,  5.0365e-03, -6.0532e-04,\n",
       "          5.6875e-03,  1.0549e-03,  5.7518e-03],\n",
       "        [-9.8001e-05, -6.9819e-05,  7.9965e-04,  2.5785e-03,  1.7354e-03,\n",
       "          3.3845e-03,  3.2947e-03,  3.3999e-03],\n",
       "        [ 3.6220e-04, -6.8500e-04,  1.1571e-03,  2.0625e-03,  2.0833e-03,\n",
       "          3.1642e-03,  3.5781e-03,  3.0244e-03],\n",
       "        [-3.5186e-04,  2.5896e-04,  5.9208e-04,  2.7187e-03,  1.5309e-03,\n",
       "          3.5178e-03,  3.2141e-03,  3.5840e-03],\n",
       "        [-4.0713e-04,  4.0418e-04,  5.0593e-04,  2.8183e-03,  1.3743e-03,\n",
       "          3.6138e-03,  3.1044e-03,  3.7253e-03],\n",
       "        [-1.4800e-03,  1.6859e-03, -3.4532e-04,  3.9402e-03,  2.3816e-04,\n",
       "          4.6036e-03,  2.0713e-03,  4.7771e-03],\n",
       "        [-1.3407e-03,  1.5733e-03, -2.5905e-04,  3.8852e-03,  2.8924e-04,\n",
       "          4.4829e-03,  2.0427e-03,  4.7192e-03],\n",
       "        [-6.2718e-04,  8.0165e-04,  3.0038e-04,  3.1445e-03,  9.8081e-04,\n",
       "          3.8702e-03,  2.7678e-03,  4.0721e-03],\n",
       "        [-4.5184e-04,  5.7162e-04,  4.2029e-04,  3.0110e-03,  1.1508e-03,\n",
       "          3.7440e-03,  2.8993e-03,  3.9115e-03],\n",
       "        [-9.2465e-04,  1.0659e-03,  1.5724e-04,  3.3093e-03,  7.9817e-04,\n",
       "          4.0389e-03,  2.6652e-03,  4.2197e-03],\n",
       "        [-5.4559e-04,  5.3921e-04,  4.3930e-04,  2.9250e-03,  1.2948e-03,\n",
       "          3.6800e-03,  3.0304e-03,  3.7908e-03],\n",
       "        [-2.6360e-04,  3.2900e-04,  5.5958e-04,  2.8360e-03,  1.3495e-03,\n",
       "          3.6054e-03,  3.0461e-03,  3.7433e-03],\n",
       "        [-9.3145e-03,  1.1615e-02, -7.2709e-03,  1.1010e-02, -5.4916e-03,\n",
       "          1.0583e-02, -4.7640e-03,  1.1091e-02],\n",
       "        [-4.5242e-04,  5.5517e-04,  4.2983e-04,  2.9989e-03,  1.1636e-03,\n",
       "          3.7372e-03,  2.9013e-03,  3.9013e-03]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "cols = list(pd.concat([pd.read_parquet(\"imgs/train\"+hyper_params[\"trainset\"]+\"/target_next_20.parquet\"),\n",
    "pd.read_parquet(\"imgs/test\"+hyper_params[\"trainset\"]+\"/target_next_20.parquet\")]).iloc[:,:-1].columns)\n",
    "fcs = [[i+\"_target\",i+\"_pred\"] for i in cols]\n",
    "fullcols = [item for sublist in fcs for item in sublist]\n",
    "tl = []\n",
    "for images1,images2,images3,labels in dataiter:\n",
    "    images1 = images1.float().to(device)\n",
    "    images2 = images2.float().to(device)\n",
    "    images3 = images3.float().to(device)\n",
    "    \n",
    "    labels = labels.float().to(device)\n",
    "    outputs = net([images1,images2,images3])\n",
    "    evaldf = pd.DataFrame(labels.cpu(),columns=[i+\"_target\" for i in cols]).join(pd.DataFrame(outputs.cpu().tolist(),columns=[i+\"_pred\" for i in cols]))\n",
    "    tl.append(evaldf[fullcols])\n",
    "tf = pd.concat(tl)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a34bd7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low_5_target</th>\n",
       "      <th>Low_5_pred</th>\n",
       "      <th>High_5_target</th>\n",
       "      <th>High_5_pred</th>\n",
       "      <th>Low_10_target</th>\n",
       "      <th>Low_10_pred</th>\n",
       "      <th>High_10_target</th>\n",
       "      <th>High_10_pred</th>\n",
       "      <th>Low_15_target</th>\n",
       "      <th>Low_15_pred</th>\n",
       "      <th>High_15_target</th>\n",
       "      <th>High_15_pred</th>\n",
       "      <th>Low_20_target</th>\n",
       "      <th>Low_20_pred</th>\n",
       "      <th>High_20_target</th>\n",
       "      <th>High_20_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.001336</td>\n",
       "      <td>-0.003361</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>-0.001328</td>\n",
       "      <td>-0.002603</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>-0.004828</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>-0.001293</td>\n",
       "      <td>-0.001799</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.002093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>0.010795</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.011020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.031683</td>\n",
       "      <td>-0.045718</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.107635</td>\n",
       "      <td>-0.050941</td>\n",
       "      <td>-0.116846</td>\n",
       "      <td>-0.016854</td>\n",
       "      <td>-0.051475</td>\n",
       "      <td>-0.066908</td>\n",
       "      <td>-0.088705</td>\n",
       "      <td>-0.043833</td>\n",
       "      <td>-0.066083</td>\n",
       "      <td>-0.059140</td>\n",
       "      <td>-0.079371</td>\n",
       "      <td>-0.039862</td>\n",
       "      <td>-0.055595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.001732</td>\n",
       "      <td>-0.005694</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>-0.002212</td>\n",
       "      <td>-0.003556</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>-0.002545</td>\n",
       "      <td>-0.005371</td>\n",
       "      <td>-0.000317</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.002748</td>\n",
       "      <td>-0.002045</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>-0.002685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000888</td>\n",
       "      <td>-0.002767</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>-0.001536</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>-0.000901</td>\n",
       "      <td>-0.002351</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>-0.000918</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.000365</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>-0.001074</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>0.006221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.025987</td>\n",
       "      <td>0.043472</td>\n",
       "      <td>0.110648</td>\n",
       "      <td>0.025916</td>\n",
       "      <td>0.102393</td>\n",
       "      <td>0.059302</td>\n",
       "      <td>0.139139</td>\n",
       "      <td>0.036149</td>\n",
       "      <td>0.082934</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>0.092297</td>\n",
       "      <td>0.036223</td>\n",
       "      <td>0.050705</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.152165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Low_5_target   Low_5_pred  High_5_target  High_5_pred  Low_10_target  \\\n",
       "count   7916.000000  7916.000000    7916.000000  7916.000000    7916.000000   \n",
       "mean      -0.001336    -0.003361       0.001387     0.003542      -0.001328   \n",
       "std        0.001608     0.005693       0.001755     0.009110       0.002745   \n",
       "min       -0.031683    -0.045718      -0.000036    -0.107635      -0.050941   \n",
       "25%       -0.001732    -0.005694       0.000389     0.000669      -0.002212   \n",
       "50%       -0.000888    -0.002767       0.000913     0.001957      -0.000915   \n",
       "75%       -0.000365    -0.000042       0.001784     0.004489       0.000078   \n",
       "max        0.000047     0.025987       0.043472     0.110648       0.025916   \n",
       "\n",
       "       Low_10_pred  High_10_target  High_10_pred  Low_15_target  Low_15_pred  \\\n",
       "count  7916.000000     7916.000000   7916.000000    7916.000000  7916.000000   \n",
       "mean     -0.002603        0.001413      0.003577      -0.001297    -0.004828   \n",
       "std       0.009349        0.002813      0.010795       0.003449     0.008398   \n",
       "min      -0.116846       -0.016854     -0.051475      -0.066908    -0.088705   \n",
       "25%      -0.003556        0.000004      0.001555      -0.002545    -0.005371   \n",
       "50%      -0.001536        0.000953      0.002203      -0.000901    -0.002351   \n",
       "75%       0.000195        0.002305      0.003640       0.000387    -0.001074   \n",
       "max       0.102393        0.059302      0.139139       0.036149     0.082934   \n",
       "\n",
       "       High_15_target  High_15_pred  Low_20_target  Low_20_pred  \\\n",
       "count     7916.000000   7916.000000    7916.000000  7916.000000   \n",
       "mean         0.001353      0.000425      -0.001293    -0.001799   \n",
       "std          0.003395      0.007838       0.003944     0.004672   \n",
       "min         -0.043833     -0.066083      -0.059140    -0.079371   \n",
       "25%         -0.000317     -0.000225      -0.002748    -0.002045   \n",
       "50%          0.000942      0.001916      -0.000918    -0.001071   \n",
       "75%          0.002582      0.002587       0.000635    -0.000442   \n",
       "max          0.045371      0.092297       0.036223     0.050705   \n",
       "\n",
       "       High_20_target  High_20_pred  \n",
       "count     7916.000000   7916.000000  \n",
       "mean         0.001344      0.002093  \n",
       "std          0.003954      0.011020  \n",
       "min         -0.039862     -0.055595  \n",
       "25%         -0.000544     -0.002685  \n",
       "50%          0.000937      0.001847  \n",
       "75%          0.002813      0.006221  \n",
       "max          0.053114      0.152165  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "21df1255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low_5_target</th>\n",
       "      <th>Low_5_pred</th>\n",
       "      <th>High_5_target</th>\n",
       "      <th>High_5_pred</th>\n",
       "      <th>Low_10_target</th>\n",
       "      <th>Low_10_pred</th>\n",
       "      <th>High_10_target</th>\n",
       "      <th>High_10_pred</th>\n",
       "      <th>Low_15_target</th>\n",
       "      <th>Low_15_pred</th>\n",
       "      <th>High_15_target</th>\n",
       "      <th>High_15_pred</th>\n",
       "      <th>Low_20_target</th>\n",
       "      <th>Low_20_pred</th>\n",
       "      <th>High_20_target</th>\n",
       "      <th>High_20_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.001336</td>\n",
       "      <td>-0.002185</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>-0.001328</td>\n",
       "      <td>-0.001126</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>-0.001293</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.005487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.003410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.031683</td>\n",
       "      <td>-0.036923</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.001248</td>\n",
       "      <td>-0.050941</td>\n",
       "      <td>-0.045278</td>\n",
       "      <td>-0.016854</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>-0.066908</td>\n",
       "      <td>-0.028638</td>\n",
       "      <td>-0.043833</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>-0.059140</td>\n",
       "      <td>-0.015643</td>\n",
       "      <td>-0.039862</td>\n",
       "      <td>0.002880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>-0.003033</td>\n",
       "      <td>-0.005013</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.004167</td>\n",
       "      <td>-0.003481</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>-0.004744</td>\n",
       "      <td>-0.002345</td>\n",
       "      <td>-0.001639</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>-0.005337</td>\n",
       "      <td>-0.001034</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>0.003445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>-0.002023</td>\n",
       "      <td>-0.003232</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>-0.002694</td>\n",
       "      <td>-0.001826</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>-0.003362</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>-0.000957</td>\n",
       "      <td>0.003720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>-0.001516</td>\n",
       "      <td>-0.002411</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>-0.001865</td>\n",
       "      <td>-0.001147</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>-0.002109</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>-0.002289</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>0.003957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>-0.001155</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>-0.001361</td>\n",
       "      <td>-0.000617</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>-0.001449</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>-0.001554</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.004173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000888</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>-0.000901</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>-0.000918</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.004504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>-0.000649</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>-0.000519</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.005025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>-0.000462</td>\n",
       "      <td>-0.000517</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>0.005568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>-0.000268</td>\n",
       "      <td>-0.000287</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.005514</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.006336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>0.006139</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.007623</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.007784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.043472</td>\n",
       "      <td>0.023347</td>\n",
       "      <td>0.025916</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.059302</td>\n",
       "      <td>0.035160</td>\n",
       "      <td>0.036149</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>0.040025</td>\n",
       "      <td>0.036223</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.052506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Low_5_target   Low_5_pred  High_5_target  High_5_pred  Low_10_target  \\\n",
       "count   7916.000000  7916.000000    7916.000000  7916.000000    7916.000000   \n",
       "mean      -0.001336    -0.002185       0.001387     0.002481      -0.001328   \n",
       "std        0.001608     0.003120       0.001755     0.003319       0.002745   \n",
       "min       -0.031683    -0.036923      -0.000036    -0.001248      -0.050941   \n",
       "10%       -0.003033    -0.005013       0.000098    -0.000031      -0.004167   \n",
       "20%       -0.002023    -0.003232       0.000293     0.000325      -0.002694   \n",
       "30%       -0.001516    -0.002411       0.000485     0.000650      -0.001865   \n",
       "40%       -0.001155    -0.001710       0.000692     0.000954      -0.001361   \n",
       "50%       -0.000888    -0.001184       0.000913     0.001381      -0.000915   \n",
       "60%       -0.000649    -0.000770       0.001194     0.001926      -0.000519   \n",
       "70%       -0.000462    -0.000517       0.001560     0.002664      -0.000146   \n",
       "80%       -0.000268    -0.000287       0.002077     0.003716       0.000285   \n",
       "90%       -0.000085    -0.000051       0.003059     0.006139       0.001005   \n",
       "max        0.000047     0.000551       0.043472     0.023347       0.025916   \n",
       "\n",
       "       Low_10_pred  High_10_target  High_10_pred  Low_15_target  Low_15_pred  \\\n",
       "count  7916.000000     7916.000000   7916.000000    7916.000000  7916.000000   \n",
       "mean     -0.001126        0.001413      0.004590      -0.001297    -0.000213   \n",
       "std       0.003323        0.002813      0.002938       0.003449     0.002602   \n",
       "min      -0.045278       -0.016854      0.001550      -0.066908    -0.028638   \n",
       "10%      -0.003481       -0.000964      0.002604      -0.004744    -0.002345   \n",
       "20%      -0.001826       -0.000228      0.002839      -0.003058    -0.001022   \n",
       "30%      -0.001147        0.000216      0.003045      -0.002109    -0.000442   \n",
       "40%      -0.000617        0.000601      0.003250      -0.001449     0.000011   \n",
       "50%      -0.000081        0.000953      0.003661      -0.000901     0.000476   \n",
       "60%       0.000220        0.001386      0.004234      -0.000409     0.000861   \n",
       "70%       0.000382        0.001937      0.004821       0.000090     0.001105   \n",
       "80%       0.000567        0.002775      0.005514       0.000703     0.001370   \n",
       "90%       0.000770        0.004225      0.007173       0.001739     0.001680   \n",
       "max       0.001473        0.059302      0.035160       0.036149     0.002324   \n",
       "\n",
       "       High_15_target  High_15_pred  Low_20_target  Low_20_pred  \\\n",
       "count     7916.000000   7916.000000    7916.000000  7916.000000   \n",
       "mean         0.001353      0.005238      -0.001293     0.001442   \n",
       "std          0.003395      0.002814       0.003944     0.002518   \n",
       "min         -0.043833      0.003164      -0.059140    -0.015643   \n",
       "10%         -0.001639      0.003390      -0.005337    -0.001034   \n",
       "20%         -0.000656      0.003596      -0.003362     0.000491   \n",
       "30%         -0.000023      0.003782      -0.002289     0.001248   \n",
       "40%          0.000466      0.003962      -0.001554     0.001830   \n",
       "50%          0.000942      0.004313      -0.000918     0.002321   \n",
       "60%          0.001500      0.004818      -0.000361     0.002681   \n",
       "70%          0.002163      0.005454       0.000258     0.002868   \n",
       "80%          0.003090      0.006239       0.001030     0.003049   \n",
       "90%          0.004824      0.007623       0.002319     0.003264   \n",
       "max          0.045371      0.040025       0.036223     0.003978   \n",
       "\n",
       "       High_20_target  High_20_pred  \n",
       "count     7916.000000   7916.000000  \n",
       "mean         0.001344      0.005487  \n",
       "std          0.003954      0.003410  \n",
       "min         -0.039862      0.002880  \n",
       "10%         -0.002157      0.003445  \n",
       "20%         -0.000957      0.003720  \n",
       "30%         -0.000209      0.003957  \n",
       "40%          0.000384      0.004173  \n",
       "50%          0.000937      0.004504  \n",
       "60%          0.001586      0.005025  \n",
       "70%          0.002331      0.005568  \n",
       "80%          0.003383      0.006336  \n",
       "90%          0.005317      0.007784  \n",
       "max          0.053114      0.052506  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.describe(percentiles=[i/10 for i in range(1,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4c9a9b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low_5_target</th>\n",
       "      <th>Low_5_pred</th>\n",
       "      <th>High_5_target</th>\n",
       "      <th>High_5_pred</th>\n",
       "      <th>Low_10_target</th>\n",
       "      <th>Low_10_pred</th>\n",
       "      <th>High_10_target</th>\n",
       "      <th>High_10_pred</th>\n",
       "      <th>Low_15_target</th>\n",
       "      <th>Low_15_pred</th>\n",
       "      <th>High_15_target</th>\n",
       "      <th>High_15_pred</th>\n",
       "      <th>Low_20_target</th>\n",
       "      <th>Low_20_pred</th>\n",
       "      <th>High_20_target</th>\n",
       "      <th>High_20_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "      <td>7916.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.001336</td>\n",
       "      <td>-0.002470</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>-0.001328</td>\n",
       "      <td>-0.003138</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>-0.001292</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>-0.001293</td>\n",
       "      <td>-0.003519</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>-0.000568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.000972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.031683</td>\n",
       "      <td>-0.008992</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>-0.050941</td>\n",
       "      <td>-0.005699</td>\n",
       "      <td>-0.016854</td>\n",
       "      <td>-0.000715</td>\n",
       "      <td>-0.066908</td>\n",
       "      <td>-0.010059</td>\n",
       "      <td>-0.043833</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>-0.059140</td>\n",
       "      <td>-0.007830</td>\n",
       "      <td>-0.039862</td>\n",
       "      <td>-0.001956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>-0.003033</td>\n",
       "      <td>-0.003730</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>-0.004167</td>\n",
       "      <td>-0.004210</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>-0.004744</td>\n",
       "      <td>-0.002238</td>\n",
       "      <td>-0.001639</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>-0.005337</td>\n",
       "      <td>-0.004558</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>-0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>-0.002023</td>\n",
       "      <td>-0.003119</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>-0.002694</td>\n",
       "      <td>-0.003774</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>-0.003362</td>\n",
       "      <td>-0.004170</td>\n",
       "      <td>-0.000957</td>\n",
       "      <td>-0.001294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>-0.001516</td>\n",
       "      <td>-0.002715</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>-0.001865</td>\n",
       "      <td>-0.003447</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>-0.002109</td>\n",
       "      <td>-0.001558</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>-0.002289</td>\n",
       "      <td>-0.003846</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>-0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>-0.001155</td>\n",
       "      <td>-0.002419</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>-0.001361</td>\n",
       "      <td>-0.003183</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-0.001449</td>\n",
       "      <td>-0.001298</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.001554</td>\n",
       "      <td>-0.003561</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>-0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000888</td>\n",
       "      <td>-0.002183</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>-0.000901</td>\n",
       "      <td>-0.001092</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>-0.000918</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>-0.000818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>-0.000649</td>\n",
       "      <td>-0.002011</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>-0.000519</td>\n",
       "      <td>-0.002805</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.000954</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>-0.003162</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>-0.000565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>-0.000462</td>\n",
       "      <td>-0.001886</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.000849</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>-0.003041</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>-0.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>-0.000268</td>\n",
       "      <td>-0.001735</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>-0.002907</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.001531</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-0.002336</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>-0.000469</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>-0.002709</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>0.043472</td>\n",
       "      <td>0.012532</td>\n",
       "      <td>0.025916</td>\n",
       "      <td>-0.001862</td>\n",
       "      <td>0.059302</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.036149</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.036223</td>\n",
       "      <td>-0.002261</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.008488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Low_5_target   Low_5_pred  High_5_target  High_5_pred  Low_10_target  \\\n",
       "count   7916.000000  7916.000000    7916.000000  7916.000000    7916.000000   \n",
       "mean      -0.001336    -0.002470       0.001387     0.002068      -0.001328   \n",
       "std        0.001608     0.000970       0.001755     0.000965       0.002745   \n",
       "min       -0.031683    -0.008992      -0.000036     0.000716      -0.050941   \n",
       "10%       -0.003033    -0.003730       0.000098     0.001132      -0.004167   \n",
       "20%       -0.002023    -0.003119       0.000293     0.001369      -0.002694   \n",
       "30%       -0.001516    -0.002715       0.000485     0.001519      -0.001865   \n",
       "40%       -0.001155    -0.002419       0.000692     0.001640      -0.001361   \n",
       "50%       -0.000888    -0.002183       0.000913     0.001809      -0.000915   \n",
       "60%       -0.000649    -0.002011       0.001194     0.002041      -0.000519   \n",
       "70%       -0.000462    -0.001886       0.001560     0.002326      -0.000146   \n",
       "80%       -0.000268    -0.001735       0.002077     0.002688       0.000285   \n",
       "90%       -0.000085    -0.001531       0.003059     0.003169       0.001005   \n",
       "max        0.000047    -0.000976       0.043472     0.012532       0.025916   \n",
       "\n",
       "       Low_10_pred  High_10_target  High_10_pred  Low_15_target  Low_15_pred  \\\n",
       "count  7916.000000     7916.000000   7916.000000    7916.000000  7916.000000   \n",
       "mean     -0.003138        0.001413      0.000726      -0.001297    -0.001292   \n",
       "std       0.000699        0.002813      0.000953       0.003449     0.000787   \n",
       "min      -0.005699       -0.016854     -0.000715      -0.066908    -0.010059   \n",
       "10%      -0.004210       -0.000964     -0.000228      -0.004744    -0.002238   \n",
       "20%      -0.003774       -0.000228     -0.000012      -0.003058    -0.001844   \n",
       "30%      -0.003447        0.000216      0.000140      -0.002109    -0.001558   \n",
       "40%      -0.003183        0.000601      0.000280      -0.001449    -0.001298   \n",
       "50%      -0.002969        0.000953      0.000468      -0.000901    -0.001092   \n",
       "60%      -0.002805        0.001386      0.000709      -0.000409    -0.000954   \n",
       "70%      -0.002683        0.001937      0.000980       0.000090    -0.000849   \n",
       "80%      -0.002538        0.002775      0.001354       0.000703    -0.000708   \n",
       "90%      -0.002336        0.004225      0.002034       0.001739    -0.000469   \n",
       "max      -0.001862        0.059302      0.006731       0.036149    -0.000021   \n",
       "\n",
       "       High_15_target  High_15_pred  Low_20_target  Low_20_pred  \\\n",
       "count     7916.000000   7916.000000    7916.000000  7916.000000   \n",
       "mean         0.001353      0.001696      -0.001293    -0.003519   \n",
       "std          0.003395      0.000790       0.003944     0.000719   \n",
       "min         -0.043833      0.000114      -0.059140    -0.007830   \n",
       "10%         -0.001639      0.000833      -0.005337    -0.004558   \n",
       "20%         -0.000656      0.001065      -0.003362    -0.004170   \n",
       "30%         -0.000023      0.001217      -0.002289    -0.003846   \n",
       "40%          0.000466      0.001340      -0.001554    -0.003561   \n",
       "50%          0.000942      0.001508      -0.000918    -0.003325   \n",
       "60%          0.001500      0.001718      -0.000361    -0.003162   \n",
       "70%          0.002163      0.001980       0.000258    -0.003041   \n",
       "80%          0.003090      0.002331       0.001030    -0.002907   \n",
       "90%          0.004824      0.002816       0.002319    -0.002709   \n",
       "max          0.045371      0.005654       0.036223    -0.002261   \n",
       "\n",
       "       High_20_target  High_20_pred  \n",
       "count     7916.000000   7916.000000  \n",
       "mean         0.001344     -0.000568  \n",
       "std          0.003954      0.000972  \n",
       "min         -0.039862     -0.001956  \n",
       "10%         -0.002157     -0.001543  \n",
       "20%         -0.000957     -0.001294  \n",
       "30%         -0.000209     -0.001133  \n",
       "40%          0.000384     -0.001002  \n",
       "50%          0.000937     -0.000818  \n",
       "60%          0.001586     -0.000565  \n",
       "70%          0.002331     -0.000255  \n",
       "80%          0.003383      0.000095  \n",
       "90%          0.005317      0.000561  \n",
       "max          0.053114      0.008488  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.describe(percentiles=[i/10 for i in range(1,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "aa4afbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low_5_target</th>\n",
       "      <th>Low_5_pred</th>\n",
       "      <th>High_5_target</th>\n",
       "      <th>High_5_pred</th>\n",
       "      <th>Low_10_target</th>\n",
       "      <th>Low_10_pred</th>\n",
       "      <th>High_10_target</th>\n",
       "      <th>High_10_pred</th>\n",
       "      <th>Low_15_target</th>\n",
       "      <th>Low_15_pred</th>\n",
       "      <th>High_15_target</th>\n",
       "      <th>High_15_pred</th>\n",
       "      <th>Low_20_target</th>\n",
       "      <th>Low_20_pred</th>\n",
       "      <th>High_20_target</th>\n",
       "      <th>High_20_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000453</td>\n",
       "      <td>-0.002150</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>-0.003044</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>-0.001168</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>-0.003460</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>-0.000761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001320</td>\n",
       "      <td>-0.002920</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>-0.003489</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>-0.001636</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>-0.001139</td>\n",
       "      <td>-0.003969</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>-0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001993</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>-0.002768</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>-0.003179</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>-0.001045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000169</td>\n",
       "      <td>-0.002720</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>-0.003573</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>-0.001680</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>-0.004061</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>-0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.002354</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>-0.000280</td>\n",
       "      <td>-0.000910</td>\n",
       "      <td>-0.000383</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>-0.002675</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>-0.001586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.000878</td>\n",
       "      <td>-0.003497</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>-0.004264</td>\n",
       "      <td>0.007772</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>-0.002355</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>-0.004550</td>\n",
       "      <td>0.008567</td>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>-0.003206</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>-0.001240</td>\n",
       "      <td>0.010126</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>-0.003585</td>\n",
       "      <td>0.010094</td>\n",
       "      <td>-0.000583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.002132</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>-0.002948</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>-0.003395</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>-0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.000981</td>\n",
       "      <td>-0.003234</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>-0.003933</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>-0.001906</td>\n",
       "      <td>-0.001752</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>-0.000738</td>\n",
       "      <td>-0.004377</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.000186</td>\n",
       "      <td>-0.001505</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>-0.000755</td>\n",
       "      <td>-0.002304</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>-0.000352</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>-0.002755</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>-0.001512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4728 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Low_5_target  Low_5_pred  High_5_target  High_5_pred  Low_10_target  \\\n",
       "0      -0.000453   -0.002150       0.002245     0.001788       0.002017   \n",
       "1      -0.001320   -0.002920       0.005935     0.002476      -0.000186   \n",
       "2       0.000000   -0.001993       0.004065     0.001630       0.001436   \n",
       "3      -0.000169   -0.002720       0.001787     0.002332       0.000807   \n",
       "4      -0.000004   -0.001524       0.000684     0.001169      -0.000096   \n",
       "..           ...         ...            ...          ...            ...   \n",
       "30     -0.000878   -0.003497       0.000831     0.003066       0.000549   \n",
       "32     -0.000032   -0.002300       0.005154     0.001942       0.004327   \n",
       "36      0.000020   -0.002132       0.002205     0.001757       0.000609   \n",
       "38     -0.000981   -0.003234       0.001764     0.002696      -0.001173   \n",
       "43     -0.000186   -0.001505       0.001137     0.001120      -0.000755   \n",
       "\n",
       "    Low_10_pred  High_10_target  High_10_pred  Low_15_target  Low_15_pred  \\\n",
       "0     -0.003044        0.004239      0.000423       0.002554    -0.001168   \n",
       "1     -0.003489        0.004533      0.001044       0.000867    -0.001636   \n",
       "2     -0.002768        0.005135      0.000183       0.003342    -0.000987   \n",
       "3     -0.003573        0.003072      0.001143       0.001618    -0.001680   \n",
       "4     -0.002354        0.000595     -0.000280      -0.000910    -0.000383   \n",
       "..          ...             ...           ...            ...          ...   \n",
       "30    -0.004264        0.007772      0.001963       0.004140    -0.002355   \n",
       "32    -0.003206        0.006003      0.000673       0.004191    -0.001240   \n",
       "36    -0.002948        0.002858      0.000365       0.000609    -0.001173   \n",
       "38    -0.003933       -0.000056      0.001398      -0.001906    -0.001752   \n",
       "43    -0.002304        0.000805     -0.000284      -0.000352    -0.000491   \n",
       "\n",
       "    High_15_target  High_15_pred  Low_20_target  Low_20_pred  High_20_target  \\\n",
       "0         0.004029      0.001572       0.002792    -0.003460        0.004602   \n",
       "1         0.003199      0.002041      -0.001139    -0.003969        0.003226   \n",
       "2         0.004743      0.001299       0.003659    -0.003179        0.008794   \n",
       "3         0.003105      0.002096       0.001735    -0.004061        0.002641   \n",
       "4         0.001967      0.000880       0.001245    -0.002675        0.003342   \n",
       "..             ...           ...            ...          ...             ...   \n",
       "30        0.006094      0.002758       0.005321    -0.004550        0.008567   \n",
       "32        0.010126      0.001711       0.007519    -0.003585        0.010094   \n",
       "36        0.002554      0.001479       0.000095    -0.003395        0.001836   \n",
       "38        0.000399      0.002516      -0.000738    -0.004377        0.001259   \n",
       "43        0.000880      0.000783       0.000387    -0.002755        0.002505   \n",
       "\n",
       "    High_20_pred  \n",
       "0      -0.000761  \n",
       "1      -0.000177  \n",
       "2      -0.001045  \n",
       "3      -0.000102  \n",
       "4      -0.001586  \n",
       "..           ...  \n",
       "30      0.000463  \n",
       "32     -0.000583  \n",
       "36     -0.000839  \n",
       "38      0.000083  \n",
       "43     -0.001512  \n",
       "\n",
       "[4728 rows x 16 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf[tf.Low_5_pred*0.5<tf.Low_5_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "91e9b617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low_5_target</th>\n",
       "      <th>Low_5_pred</th>\n",
       "      <th>High_5_target</th>\n",
       "      <th>High_5_pred</th>\n",
       "      <th>Low_10_target</th>\n",
       "      <th>Low_10_pred</th>\n",
       "      <th>High_10_target</th>\n",
       "      <th>High_10_pred</th>\n",
       "      <th>Low_15_target</th>\n",
       "      <th>Low_15_pred</th>\n",
       "      <th>High_15_target</th>\n",
       "      <th>High_15_pred</th>\n",
       "      <th>Low_20_target</th>\n",
       "      <th>Low_20_pred</th>\n",
       "      <th>High_20_target</th>\n",
       "      <th>High_20_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000453</td>\n",
       "      <td>-0.002150</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>-0.003044</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>-0.001168</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>-0.003460</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>-0.000761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001320</td>\n",
       "      <td>-0.002920</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>-0.003489</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>-0.001636</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>-0.001139</td>\n",
       "      <td>-0.003969</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>-0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001993</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>-0.002768</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>-0.003179</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>-0.001045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000169</td>\n",
       "      <td>-0.002720</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>-0.003573</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>-0.001680</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>-0.004061</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>-0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.002354</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>-0.000280</td>\n",
       "      <td>-0.000910</td>\n",
       "      <td>-0.000383</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>-0.002675</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>-0.001586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.003360</td>\n",
       "      <td>-0.001644</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>-0.002313</td>\n",
       "      <td>-0.002449</td>\n",
       "      <td>-0.001531</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.002679</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.003096</td>\n",
       "      <td>-0.002816</td>\n",
       "      <td>-0.001977</td>\n",
       "      <td>-0.001444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>-0.002284</td>\n",
       "      <td>-0.002230</td>\n",
       "      <td>-0.001659</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>-0.000755</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>-0.003187</td>\n",
       "      <td>-0.002548</td>\n",
       "      <td>-0.001205</td>\n",
       "      <td>-0.001721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.003124</td>\n",
       "      <td>-0.002132</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>-0.002170</td>\n",
       "      <td>-0.002962</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>-0.001075</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003337</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>-0.000826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.003117</td>\n",
       "      <td>-0.003202</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>-0.007422</td>\n",
       "      <td>-0.003990</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>-0.007224</td>\n",
       "      <td>-0.001865</td>\n",
       "      <td>-0.001667</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>-0.008085</td>\n",
       "      <td>-0.004315</td>\n",
       "      <td>-0.002721</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.000186</td>\n",
       "      <td>-0.001505</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>-0.000755</td>\n",
       "      <td>-0.002304</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>-0.000352</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>-0.002755</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>-0.001512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7916 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Low_5_target  Low_5_pred  High_5_target  High_5_pred  Low_10_target  \\\n",
       "0      -0.000453   -0.002150       0.002245     0.001788       0.002017   \n",
       "1      -0.001320   -0.002920       0.005935     0.002476      -0.000186   \n",
       "2       0.000000   -0.001993       0.004065     0.001630       0.001436   \n",
       "3      -0.000169   -0.002720       0.001787     0.002332       0.000807   \n",
       "4      -0.000004   -0.001524       0.000684     0.001169      -0.000096   \n",
       "..           ...         ...            ...          ...            ...   \n",
       "39     -0.003360   -0.001644       0.000437     0.001223      -0.002313   \n",
       "40     -0.002022   -0.001400       0.000306     0.000961      -0.002284   \n",
       "41     -0.003124   -0.002132       0.001012     0.001767      -0.002170   \n",
       "42     -0.003117   -0.003202       0.002039     0.002754      -0.007422   \n",
       "43     -0.000186   -0.001505       0.001137     0.001120      -0.000755   \n",
       "\n",
       "    Low_10_pred  High_10_target  High_10_pred  Low_15_target  Low_15_pred  \\\n",
       "0     -0.003044        0.004239      0.000423       0.002554    -0.001168   \n",
       "1     -0.003489        0.004533      0.001044       0.000867    -0.001636   \n",
       "2     -0.002768        0.005135      0.000183       0.003342    -0.000987   \n",
       "3     -0.003573        0.003072      0.001143       0.001618    -0.001680   \n",
       "4     -0.002354        0.000595     -0.000280      -0.000910    -0.000383   \n",
       "..          ...             ...           ...            ...          ...   \n",
       "39    -0.002449       -0.001531     -0.000050      -0.002679    -0.000479   \n",
       "40    -0.002230       -0.001659     -0.000386      -0.001882    -0.000273   \n",
       "41    -0.002962        0.000145      0.000445      -0.000731    -0.001075   \n",
       "42    -0.003990       -0.000515      0.001676      -0.007224    -0.001865   \n",
       "43    -0.002304        0.000805     -0.000284      -0.000352    -0.000491   \n",
       "\n",
       "    High_15_target  High_15_pred  Low_20_target  Low_20_pred  High_20_target  \\\n",
       "0         0.004029      0.001572       0.002792    -0.003460        0.004602   \n",
       "1         0.003199      0.002041      -0.001139    -0.003969        0.003226   \n",
       "2         0.004743      0.001299       0.003659    -0.003179        0.008794   \n",
       "3         0.003105      0.002096       0.001735    -0.004061        0.002641   \n",
       "4         0.001967      0.000880       0.001245    -0.002675        0.003342   \n",
       "..             ...           ...            ...          ...             ...   \n",
       "39       -0.001813      0.000997      -0.003096    -0.002816       -0.001977   \n",
       "40       -0.000755      0.000696      -0.003187    -0.002548       -0.001205   \n",
       "41        0.001681      0.001519       0.000000    -0.003337        0.003299   \n",
       "42       -0.001667      0.002575      -0.008085    -0.004315       -0.002721   \n",
       "43        0.000880      0.000783       0.000387    -0.002755        0.002505   \n",
       "\n",
       "    High_20_pred  \n",
       "0      -0.000761  \n",
       "1      -0.000177  \n",
       "2      -0.001045  \n",
       "3      -0.000102  \n",
       "4      -0.001586  \n",
       "..           ...  \n",
       "39     -0.001444  \n",
       "40     -0.001721  \n",
       "41     -0.000826  \n",
       "42      0.000245  \n",
       "43     -0.001512  \n",
       "\n",
       "[7916 rows x 16 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f748d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
